{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path to the nc file (here I used a relative path and the file and this notebook are in the same directory)\n",
    "file_path = 'P5023_magnetic_gradient_reduced.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at top-level groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['line_index',\n",
       " 'line',\n",
       " 'FLIGHT',\n",
       " 'DATE',\n",
       " 'EASTING',\n",
       " 'FIDUCIAL',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'NORTHING',\n",
       " 'diurnal',\n",
       " 'gnss_height_geoid',\n",
       " 'gradient_longitudinal_lev',\n",
       " 'gradient_transverse_lev',\n",
       " 'igrf',\n",
       " 'line_type',\n",
       " 'mag_1_diur_igrf',\n",
       " 'mag_1_diur_igrf_tie',\n",
       " 'mag_1_diur_igrf_tie_micro',\n",
       " 'pseudo_fid',\n",
       " 'pseudo_line',\n",
       " 'radar_calib_edit',\n",
       " 'radar_dem',\n",
       " 'point',\n",
       " 'crs']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of groups\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    groups = list(f.keys())\n",
    "\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Group Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: line_index\n",
      "  Dataset: line_index - Shape: (24029501,), Dtype: uint32\n",
      "Group: line\n",
      "  Dataset: line - Shape: (802,), Dtype: uint32\n",
      "Group: FLIGHT\n",
      "  Dataset: FLIGHT - Shape: (802,), Dtype: int32\n",
      "Group: DATE\n",
      "  Dataset: DATE - Shape: (24029501,), Dtype: int32\n",
      "Group: EASTING\n",
      "  Dataset: EASTING - Shape: (24029501,), Dtype: float64\n",
      "Group: FIDUCIAL\n",
      "  Dataset: FIDUCIAL - Shape: (24029501,), Dtype: int32\n",
      "Group: latitude\n",
      "  Dataset: latitude - Shape: (24029501,), Dtype: float64\n",
      "Group: longitude\n",
      "  Dataset: longitude - Shape: (24029501,), Dtype: float64\n",
      "Group: NORTHING\n",
      "  Dataset: NORTHING - Shape: (24029501,), Dtype: float64\n",
      "Group: diurnal\n",
      "  Dataset: diurnal - Shape: (24029501,), Dtype: float64\n",
      "Group: gnss_height_geoid\n",
      "  Dataset: gnss_height_geoid - Shape: (24029501,), Dtype: float64\n",
      "Group: gradient_longitudinal_lev\n",
      "  Dataset: gradient_longitudinal_lev - Shape: (24029501,), Dtype: float64\n",
      "Group: gradient_transverse_lev\n",
      "  Dataset: gradient_transverse_lev - Shape: (24029501,), Dtype: float64\n",
      "Group: igrf\n",
      "  Dataset: igrf - Shape: (24029501,), Dtype: float64\n",
      "Group: line_type\n",
      "  Dataset: line_type - Shape: (24029501,), Dtype: float64\n",
      "Group: mag_1_diur_igrf\n",
      "  Dataset: mag_1_diur_igrf - Shape: (24029501,), Dtype: float64\n",
      "Group: mag_1_diur_igrf_tie\n",
      "  Dataset: mag_1_diur_igrf_tie - Shape: (24029501,), Dtype: float64\n",
      "Group: mag_1_diur_igrf_tie_micro\n",
      "  Dataset: mag_1_diur_igrf_tie_micro - Shape: (24029501,), Dtype: float64\n",
      "Group: pseudo_fid\n",
      "  Dataset: pseudo_fid - Shape: (24029501,), Dtype: int32\n",
      "Group: pseudo_line\n",
      "  Dataset: pseudo_line - Shape: (24029501,), Dtype: int32\n",
      "Group: radar_calib_edit\n",
      "  Dataset: radar_calib_edit - Shape: (24029501,), Dtype: float64\n",
      "Group: radar_dem\n",
      "  Dataset: radar_dem - Shape: (24029501,), Dtype: float64\n",
      "Group: point\n",
      "  Dataset: point - Shape: (24029501,), Dtype: >f4\n",
      "Group: crs\n",
      "  Dataset: crs - Shape: (), Dtype: int8\n"
     ]
    }
   ],
   "source": [
    "# Inspect the contents of the groups in the HDF5 file\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    for group_name in f.keys():  # Iterate through the top-level groups\n",
    "        print(f\"Group: {group_name}\")  # Print the name of the group\n",
    "        group = f[group_name]  # Access the group\n",
    "        if isinstance(group, h5py.Group):  # Check if it is a subgroup\n",
    "            print(\"  Subgroups/Datasets:\")  # Indicate that subgroups or datasets exist\n",
    "            for item_name in group.keys():  # Iterate through items in the subgroup\n",
    "                item = group[item_name]  # Access the item\n",
    "                if isinstance(item, h5py.Group):  # Check if the item is a subgroup\n",
    "                    print(f\"    Subgroup: {item_name}\")  # Print the name of the subgroup\n",
    "                elif isinstance(item, h5py.Dataset):  # Check if the item is a dataset\n",
    "                    # Print the name, shape, and data type of the dataset\n",
    "                    print(f\"    Dataset: {item_name} - Shape: {item.shape}, Dtype: {item.dtype}\")\n",
    "        elif isinstance(group, h5py.Dataset):  # Check if the top-level group is a dataset\n",
    "            # Print the name, shape, and data type of the dataset\n",
    "            print(f\"  Dataset: {group_name} - Shape: {group.shape}, Dtype: {group.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data From Datasets and Store Them in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: line_index\n",
      "Loading dataset: line\n",
      "Loading dataset: FLIGHT\n",
      "Loading dataset: DATE\n",
      "Loading dataset: EASTING\n",
      "Loading dataset: FIDUCIAL\n",
      "Loading dataset: latitude\n",
      "Loading dataset: longitude\n",
      "Loading dataset: NORTHING\n",
      "Loading dataset: diurnal\n",
      "Loading dataset: gnss_height_geoid\n",
      "Loading dataset: gradient_longitudinal_lev\n",
      "Loading dataset: gradient_transverse_lev\n",
      "Loading dataset: igrf\n",
      "Loading dataset: line_type\n",
      "Loading dataset: mag_1_diur_igrf\n",
      "Loading dataset: mag_1_diur_igrf_tie\n",
      "Loading dataset: mag_1_diur_igrf_tie_micro\n",
      "Loading dataset: pseudo_fid\n",
      "Loading dataset: pseudo_line\n",
      "Loading dataset: radar_calib_edit\n",
      "Loading dataset: radar_dem\n",
      "Loading dataset: point\n",
      "Loading dataset: crs\n",
      "   line_index      line  FLIGHT      DATE    EASTING  FIDUCIAL   latitude  \\\n",
      "0           0  190180.0     2.0  20230522  355950.44   2120000 -31.800268   \n",
      "1           0  100010.0     2.0  20230522  355950.41   2120050 -31.800291   \n",
      "2           0  100020.0     2.0  20230522  355950.38   2120100 -31.800313   \n",
      "3           0  100030.0     2.0  20230522  355950.35   2120150 -31.800336   \n",
      "4           0  100040.0     2.0  20230522  355950.32   2120200 -31.800359   \n",
      "\n",
      "    longitude    NORTHING    diurnal  ...  line_type  mag_1_diur_igrf  \\\n",
      "0  145.478315  6480694.60  56497.169  ...        4.0          -40.891   \n",
      "1  145.478314  6480692.09  56497.169  ...        4.0          -40.890   \n",
      "2  145.478314  6480689.57  56497.169  ...        4.0          -40.891   \n",
      "3  145.478313  6480687.06  56497.168  ...        4.0          -40.893   \n",
      "4  145.478312  6480684.55  56497.168  ...        4.0          -40.890   \n",
      "\n",
      "   mag_1_diur_igrf_tie  mag_1_diur_igrf_tie_micro  pseudo_fid  pseudo_line  \\\n",
      "0              -39.899                    -39.899       53340       355950   \n",
      "1              -39.897                    -39.897       53339       355950   \n",
      "2              -39.899                    -39.899       53338       355950   \n",
      "3              -39.901                    -39.901       53337       355950   \n",
      "4              -39.898                    -39.898       53336       355950   \n",
      "\n",
      "   radar_calib_edit  radar_dem  point  crs  \n",
      "0             81.77     191.19    0.0  0.0  \n",
      "1             81.87     191.11    0.0  NaN  \n",
      "2             82.00     190.99    0.0  NaN  \n",
      "3             82.12     190.89    0.0  NaN  \n",
      "4             82.11     190.92    0.0  NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store datasets\n",
    "data_dict = {}\n",
    "\n",
    "# Open the NetCDF file and extract datasets\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    for group_name in f.keys():\n",
    "        group = f[group_name]\n",
    "        if isinstance(group, h5py.Dataset):  # Check if it's a dataset\n",
    "            print(f\"Loading dataset: {group_name}\")\n",
    "            if group.shape == ():  # Check if the dataset is scalar\n",
    "                data_dict[group_name] = [group[()]]  # Wrap scalar in a list\n",
    "            else:\n",
    "                # Convert big-endian data to little-endian if necessary\n",
    "                data = group[:]\n",
    "                if data.dtype.byteorder == '>':  # Big-endian\n",
    "                    data = data.astype(data.dtype.newbyteorder('<'))  # Convert to little-endian\n",
    "                data_dict[group_name] = data  # Store the converted data\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame, automatically aligning lengths\n",
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data_dict.items()]))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a CSV file\n",
    "df.to_csv(f'{file_path}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineralvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
